{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a49b20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2c4be8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY=os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a7ec8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIzaSyCuMvow-5Fv7zoEaDSVJtOUocQxePJpQJk\n"
     ]
    }
   ],
   "source": [
    "print(GEMINI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b21d805",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_core.pydantic_v1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mGOOGLE_API_KEY\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os.environ:\n\u001b[32m      5\u001b[39m     os.environ[\u001b[33m\"\u001b[39m\u001b[33mGOOGLE_API_KEY\u001b[39m\u001b[33m\"\u001b[39m] = getpass.getpass(GEMINI_API_KEY)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[32m      8\u001b[39m model = ChatGoogleGenerativeAI(\n\u001b[32m      9\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgemini-3-pro-preview\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     temperature=\u001b[32m1.0\u001b[39m,  \u001b[38;5;66;03m# Gemini 3.0+ defaults to 1.0\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# other params...\u001b[39;00m\n\u001b[32m     15\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Allproject\\ScheduleAI\\schedule\\Lib\\site-packages\\langchain_google_genai\\__init__.py:59\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"**LangChain Google Generative AI Integration**\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mThis module integrates Google's Generative AI models, specifically the Gemini series, with the LangChain framework. It provides classes for interacting with chat models and generating embeddings, leveraging Google's advanced AI capabilities.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m \u001b[33;03m```\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_enums\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HarmBlockThreshold, HarmCategory\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GoogleGenerativeAIEmbeddings\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenai_aqa\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     62\u001b[39m     AqaInput,\n\u001b[32m     63\u001b[39m     AqaOutput,\n\u001b[32m     64\u001b[39m     GenAIAqa,\n\u001b[32m     65\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Allproject\\ScheduleAI\\schedule\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:45\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     37\u001b[39m     AIMessage,\n\u001b[32m     38\u001b[39m     AIMessageChunk,\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m     SystemMessage,\n\u001b[32m     43\u001b[39m )\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moutputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGeneration, ChatGenerationChunk, ChatResult\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpydantic_v1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SecretStr, root_validator\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_from_dict_or_env\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtenacity\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     48\u001b[39m     before_sleep_log,\n\u001b[32m     49\u001b[39m     retry,\n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m     wait_exponential,\n\u001b[32m     53\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_core.pydantic_v1'"
     ]
    }
   ],
   "source": [
    "# import getpass\n",
    "# import os\n",
    "\n",
    "# if \"GOOGLE_API_KEY\" not in os.environ:\n",
    "#     os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(GEMINI_API_KEY)\n",
    "# from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "# model = ChatGoogleGenerativeAI(\n",
    "#     model=\"gemini-3-pro-preview\",\n",
    "#     temperature=1.0,  # Gemini 3.0+ defaults to 1.0\n",
    "#     max_tokens=None,\n",
    "#     timeout=None,\n",
    "#     max_retries=2,\n",
    "#     # other params...\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3430bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.invoke(\"Explain RAG in simple terms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3b9eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\Desktop\\Allproject\\ScheduleAI\\schedule\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_core.pydantic_v1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m init_chat_model\n\u001b[32m      4\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mGOOGLE_API_KEY\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mGEMINI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m model = \u001b[43minit_chat_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgoogle_genai:gemini-2.5-flash-lite\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mgoogle_api_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGEMINI_API_KEY\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Allproject\\ScheduleAI\\schedule\\Lib\\site-packages\\langchain\\chat_models\\base.py:316\u001b[39m, in \u001b[36minit_chat_model\u001b[39m\u001b[34m(model, model_provider, configurable_fields, config_prefix, **kwargs)\u001b[39m\n\u001b[32m    308\u001b[39m     warnings.warn(\n\u001b[32m    309\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_prefix\u001b[38;5;132;01m=}\u001b[39;00m\u001b[33m has been set but no fields are configurable. Set \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    310\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`configurable_fields=(...)` to specify the model params that are \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    311\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mconfigurable.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    312\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    313\u001b[39m     )\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m configurable_fields:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_init_chat_model_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_provider\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model:\n\u001b[32m    322\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = model\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Allproject\\ScheduleAI\\schedule\\Lib\\site-packages\\langchain\\chat_models\\base.py:371\u001b[39m, in \u001b[36m_init_chat_model_helper\u001b[39m\u001b[34m(model, model_provider, **kwargs)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_provider == \u001b[33m\"\u001b[39m\u001b[33mgoogle_genai\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    370\u001b[39m     _check_pkg(\u001b[33m\"\u001b[39m\u001b[33mlangchain_google_genai\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ChatGoogleGenerativeAI(model=model, **kwargs)\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m model_provider == \u001b[33m\"\u001b[39m\u001b[33mfireworks\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Allproject\\ScheduleAI\\schedule\\Lib\\site-packages\\langchain_google_genai\\__init__.py:59\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"**LangChain Google Generative AI Integration**\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[33;03mThis module integrates Google's Generative AI models, specifically the Gemini series, with the LangChain framework. It provides classes for interacting with chat models and generating embeddings, leveraging Google's advanced AI capabilities.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     55\u001b[39m \u001b[33;03m```\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_enums\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HarmBlockThreshold, HarmCategory\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m GoogleGenerativeAIEmbeddings\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_google_genai\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgenai_aqa\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     62\u001b[39m     AqaInput,\n\u001b[32m     63\u001b[39m     AqaOutput,\n\u001b[32m     64\u001b[39m     GenAIAqa,\n\u001b[32m     65\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Allproject\\ScheduleAI\\schedule\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:45\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     37\u001b[39m     AIMessage,\n\u001b[32m     38\u001b[39m     AIMessageChunk,\n\u001b[32m   (...)\u001b[39m\u001b[32m     42\u001b[39m     SystemMessage,\n\u001b[32m     43\u001b[39m )\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moutputs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatGeneration, ChatGenerationChunk, ChatResult\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpydantic_v1\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SecretStr, root_validator\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_from_dict_or_env\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtenacity\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     48\u001b[39m     before_sleep_log,\n\u001b[32m     49\u001b[39m     retry,\n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m     wait_exponential,\n\u001b[32m     53\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'langchain_core.pydantic_v1'"
     ]
    }
   ],
   "source": [
    "# import os\n",
    "# from langchain.chat_models import init_chat_model\n",
    "\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"GEMINI_API_KEY\"\n",
    "\n",
    "# model = init_chat_model(\"google_genai:gemini-2.5-flash-lite\",google_api_key=GEMINI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecaf73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(\"Why do parrots talk?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a2bf1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parrots talk for a fascinating combination of **biological, social, and cognitive reasons**. It's not just about mimicking sounds; it's a complex behavior rooted in their evolutionary history and social structure.\n",
      "\n",
      "Here's a breakdown of why parrots talk:\n",
      "\n",
      "**1. Social Bonding and Communication:**\n",
      "\n",
      "* **Flock Animals:** Parrots are highly social creatures that live in flocks in the wild. In these large groups, effective communication is vital for survival.\n",
      "* **Maintaining Contact:** They use a variety of vocalizations, including squawks, whistles, and calls, to stay in touch with their flock members, especially when foraging or flying. Talking allows them to maintain this social connection.\n",
      "* **Strengthening Bonds:** Mimicking sounds can be a way for parrots to \"join in\" the flock's chorus, strengthening their social bonds and sense of belonging.\n",
      "\n",
      "**2. Intelligence and Cognitive Abilities:**\n",
      "\n",
      "* **Advanced Vocal Learning:** Parrots are among the few bird species that exhibit advanced vocal learning. This means they can learn and reproduce new sounds from their environment, including human speech.\n",
      "* **Brain Structure:** Their brains have specific areas dedicated to vocal learning, similar to those found in humans. This allows them to process, store, and recall sounds.\n",
      "* **Understanding Context (to some extent):** While they don't understand language in the same way humans do, some parrots can learn to associate specific words or phrases with certain objects, actions, or events. For example, they might learn to say \"hello\" when someone enters the room or \"treat\" when they see their favorite food.\n",
      "\n",
      "**3. Mimicry as a Survival Strategy (in the wild):**\n",
      "\n",
      "* **Predator Avoidance:** In their natural habitat, parrots might mimic the sounds of other animals or environmental noises to confuse predators or to blend in with their surroundings.\n",
      "* **Alarm Calls:** They might learn to mimic alarm calls of other species to alert their flock to danger.\n",
      "\n",
      "**4. Seeking Attention and Interaction (in captivity):**\n",
      "\n",
      "* **Social Creatures:** When kept as pets, parrots become part of a \"flock\" with their human family. They are intelligent and crave interaction.\n",
      "* **Getting Noticed:** Talking is a highly effective way for them to get their human flock members' attention. If a parrot learns that saying a certain word or phrase elicits a positive response (like food, petting, or conversation), they are likely to repeat it.\n",
      "* **Boredom Relief:** For intelligent and active animals like parrots, talking can also be a way to alleviate boredom and stimulate their minds.\n",
      "\n",
      "**5. Playfulness and Curiosity:**\n",
      "\n",
      "* **Exploration:** Parrots are naturally curious and enjoy exploring their environment, including sounds. Mimicking is a form of play and exploration for them.\n",
      "* **Experimentation:** They might experiment with different sounds to see what reactions they get.\n",
      "\n",
      "**In summary, parrots talk because:**\n",
      "\n",
      "* **They are social animals that need to communicate within their flocks.**\n",
      "* **They possess remarkable vocal learning abilities due to specialized brain structures.**\n",
      "* **Mimicry can be a survival advantage in the wild.**\n",
      "* **In captivity, talking is a way to seek attention, interact with their human companions, and alleviate boredom.**\n",
      "* **They are intelligent, curious, and enjoy the act of learning and producing sounds.**\n",
      "\n",
      "It's important to remember that while parrots can learn to say words, they don't understand the nuances of human language or have the same level of cognitive comprehension as humans. Their \"talking\" is a learned behavior driven by their social needs and impressive cognitive abilities.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b218cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15c2bbde",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "You are an AI assistant specialized in answering user instructions based on a collection of instructional Q&A pairs.\n",
    "\n",
    "Rules:\n",
    "1. **Follow the User Instruction Exactly**:\n",
    "   - Always prioritize the user’s instruction.\n",
    "   - If unclear, ask a clarifying question before answering.\n",
    "\n",
    "2. **Use the Provided Instruction-Answer Pairs as References**:\n",
    "   - Treat each \"instruction\" and \"answer\" pair as a knowledge source.\n",
    "   - Only provide information that can be inferred from these pairs or general knowledge.\n",
    "   - Cite the instruction explicitly when used, e.g., \"Based on the instruction: 'Explain how an LLM Twin can enhance communication efficiency.'\"\n",
    "\n",
    "3. **Answer Style**:\n",
    "   - Be concise, structured, and clear.\n",
    "   - Use numbered lists or bullet points for stepwise explanations.\n",
    "   - Summarize complex ideas in simple terms if possible.\n",
    "\n",
    "4. **Handling Missing Information**:\n",
    "   - If no relevant instruction-answer pair exists, respond: \n",
    "     \"I don’t have enough information from the provided instructions to fully answer this.\"\n",
    "\n",
    "5. **Formatting Rules**:\n",
    "   - Use markdown for code snippets.\n",
    "   - Keep responses professional and helpful.\n",
    "   - Avoid generating unrelated information.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "512e4fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PC\\Desktop\\Allproject\\ScheduleAI\\schedule\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "index_name=\"scheduleai-index\"\n",
    "model2=HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={\"device\": \"cpu\"},      # or \"cuda\" if GPU available\n",
    "    encode_kwargs={\"normalize_embeddings\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8fdc145e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'secret_from_env' from 'langchain_core.utils' (c:\\Users\\PC\\Desktop\\Allproject\\ScheduleAI\\schedule\\Lib\\site-packages\\langchain_core\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# from langchain_pinecone import PineconeVectorStore\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# doc_search=PineconeVectorStore.from_existing_index(\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m#     index_name=index_name,\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m#     embedding=model2\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_pinecone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PineconeVectorStore\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Allproject\\ScheduleAI\\schedule\\Lib\\site-packages\\langchain_pinecone\\__init__.py:1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_pinecone\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PineconeEmbeddings, PineconeSparseEmbeddings\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_pinecone\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrerank\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PineconeRerank\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_pinecone\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvectorstores\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pinecone, PineconeVectorStore\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\PC\\Desktop\\Allproject\\ScheduleAI\\schedule\\Lib\\site-packages\\langchain_pinecone\\embeddings.py:5\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Dict, Iterable, List, Optional\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01membeddings\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Embeddings\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m secret_from_env\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpinecone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pinecone \u001b[38;5;28;01mas\u001b[39;00m PineconeClient  \u001b[38;5;66;03m# type: ignore[import-untyped]\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpinecone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      8\u001b[39m     PineconeAsyncio \u001b[38;5;28;01mas\u001b[39;00m PineconeAsyncioClient,  \u001b[38;5;66;03m# type: ignore[import-untyped]\u001b[39;00m\n\u001b[32m      9\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'secret_from_env' from 'langchain_core.utils' (c:\\Users\\PC\\Desktop\\Allproject\\ScheduleAI\\schedule\\Lib\\site-packages\\langchain_core\\utils\\__init__.py)"
     ]
    }
   ],
   "source": [
    "# from langchain_pinecone import PineconeVectorStore\n",
    "# doc_search=PineconeVectorStore.from_existing_index(\n",
    "#     index_name=index_name,\n",
    "#     embedding=model2\n",
    "# )\n",
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d1b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriver=doc_search.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":3})\n",
    "user_query=\"Explain how an LLM Twin can enhance communication efficiency.\"\n",
    "retreived_ans=retriver.invoke(user_query)\n",
    "retreived_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e579797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "schedule",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
